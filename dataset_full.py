# -*- coding: utf-8 -*-
"""Dataset_Full.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/113mN7fbUSVqq7AIafl0FitUjMsn_r0vM
"""

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import MinMaxScaler
from sklearn import metrics
from sklearn.metrics import confusion_matrix
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier

data = pd.read_csv("dataset_v1.csv")
data.drop(columns=["Unnamed: 0", "Wind_spd", "Present_weather", "Past_weather", "River"], inplace = True)

"""Preprocessing"""

imputer = SimpleImputer(missing_values=pd.NA, strategy="mean")

imputer.fit(data[["Rainfall"]])
data["Rainfall"] = imputer.transform(data[["Rainfall"]])

imputer.fit(data[["Humidity"]])
data["Humidity"] = imputer.transform(data[["Humidity"]])

imputer.fit(data[["Tmax"]])
data["Tmax"] = imputer.transform(data[["Tmax"]])

imputer.fit(data[["Tmin"]])
data["Tmin"] = imputer.transform(data[["Tmin"]])

imputer.fit(data[["Cloud_amt"]])
data["Cloud_amt"] = imputer.transform(data[["Cloud_amt"]])

imputer.fit(data[["max_wl"]])
data["max_wl"] = imputer.transform(data[["max_wl"]])

imputer.fit(data[["min_wl"]])
data["min_wl"] = imputer.transform(data[["min_wl"]])

imputer = SimpleImputer(missing_values=pd.NA, strategy="most_frequent")

imputer.fit(data[["Wind_dir"]])
data["Wind_dir"] = imputer.transform(data[["Wind_dir"]])

label_encoder = LabelEncoder()
data['Wind_dir_encoded'] = label_encoder.fit_transform(data['Wind_dir'])
data[['Wind_dir', 'Wind_dir_encoded']].head()

def threshold_level(station_name):
  if station_name == "Bandarban":
    return 15.25
  if station_name == "Bogura":
    return 16.32
  if station_name == "Chattogram":
    return 4.60
  if station_name == "Chuadanga":
    return 12.05
  if station_name == "Coxs Bazar":
    return 6.25
  if station_name == "Dhaka":
    return 6.00
  if station_name == "Dinajpur":
    return 33.50
  if station_name == "Habiganj":
    return 9.50
  if station_name == "Jamalpur":
    return 17.00
  if station_name == "Mymensingh":
    return 12.50
  if station_name == "Netrokona":
    return 29.20
  if station_name == "Nilphamari":
    return 52.60
  if station_name == "Rajshahi":
    return 18.50
  if station_name == "Rangamati":
    return 17.85
  if station_name == "Rangpur":
    return 33.15
  if station_name == "Sirajganj":
    return 13.35
  if station_name == "Srimongal":
    return 11.75
  if station_name == "Sylhet":
    return 11.25
  if station_name == "Teknaf":
    return 12.25

data['Area_threshold'] = data['station'].map(threshold_level)

data['Tavg'] = (data["Tmax"] + data["Tmin"])/2
data['avg_wl'] = (data["max_wl"] + data["min_wl"])/2

data['avg_wl'] = data['avg_wl'].astype(float)
def flood_marker(water_level):
  if water_level > 0:
    return 1
  else:
    return 0

data['Flood'] = (data['Area_threshold'] - (data['avg_wl'])).map(flood_marker)

flood_True = len(data.loc[data['Flood'] == 1])
flood_False = len(data.loc[data['Flood'] == 0])
print('1s :', flood_True,'  0s :',flood_False)

"""Dataset Download"""

data.to_csv("dataset_full.csv")