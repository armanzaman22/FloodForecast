# -*- coding: utf-8 -*-
"""Full_Dataset_Algos.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1c3wD2zbRUHqwa9KEmdz9VkcRvRGkMtiU
"""

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import MinMaxScaler
from sklearn import metrics
from sklearn.metrics import confusion_matrix
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.naive_bayes import GaussianNB

data = pd.read_csv("dataset_full.csv")
data

data.drop(columns=["Unnamed: 0", "Area_threshold", "Wind_dir", "Cloud_amt"], inplace = True)
data

feature = data[["Rainfall", "Humidity", "Tmax", "Tmin", "Tavg", "max_wl", "min_wl", 'avg_wl', "Wind_dir_encoded"]]
label = data[["Flood"]]

stratY = pd.DataFrame(label)
XX=feature.values
YY=label.values
X_train, X_test, y_train, y_test = train_test_split(XX, YY, test_size = 0.25, stratify=stratY, random_state=0)

unique, counts = np.unique(y_test, return_counts=True)
aTemp = np.asarray((unique, counts)).T
print(aTemp[0][0],"->",aTemp[0][1])
print(aTemp[1][0],"->",aTemp[1][1])

print("Ratio: ", aTemp[0][1]/aTemp[1][1])

unique, counts = np.unique(y_train, return_counts=True)
aTemp = np.asarray((unique, counts)).T
print(aTemp[0][0],"->",aTemp[0][1])
print(aTemp[1][0],"->",aTemp[1][1])

print("Ratio: ", aTemp[0][1]/aTemp[1][1])

"""## Decision Tree Classifier"""

dtc = DecisionTreeClassifier(criterion='entropy',random_state=1)
dtc.fit(X_train,y_train)
y_pred_dtc = dtc.predict(X_test)

print("Accuracy for Decision Tree Classifier = {:.3f}".format(dtc.score(X_test, y_test)))
print("Error for Decision Tree Classifier = {:.3f}".format(1-dtc.score(X_test, y_test)))

LABELS = ['Flood', 'No Flood']

conf_matrix = confusion_matrix(y_train, y_pred_dtc)

plt.figure(figsize =(5, 5))

sns.heatmap(conf_matrix, xticklabels = LABELS,

			yticklabels = LABELS, annot = True, fmt ="d");

plt.title("Confusion matrix: [Decision Tree Classifier]")

plt.ylabel('True class')

plt.xlabel('Predicted class')
plt.rcParams.update({'font.size': 10})
plt.show()

"""## K-Nearest Neighbours Classifier"""

knn = KNeighborsClassifier(n_neighbors=1)
knn.fit(X_train, y_train.ravel())
y_pred_knn = knn.predict(X_test)

print("Accuracy for KNeighbors Classifier = {:.3f}".format(knn.score(X_test, y_test)))
print("Error for KNeighbors Classifier = {:.3f}".format(1-knn.score(X_test, y_test)))

LABELS = ['Flood', 'No Flood']

conf_matrix = confusion_matrix(y_test, y_pred_knn)

plt.figure(figsize =(5, 5))

sns.heatmap(conf_matrix, xticklabels = LABELS,

			yticklabels = LABELS, annot = True, fmt ="d");

plt.title("Confusion matrix: [K Nearest Neighbours Classifier]")

plt.ylabel('True class')

plt.xlabel('Predicted class')
plt.rcParams.update({'font.size': 10})
plt.show()

"""## Logistic Regression"""

lrm = LogisticRegression(max_iter=500)
lrm.fit(X_train, y_train.ravel())
y_pred_lrm = lrm.predict(X_test)

print("Accuracy for Logistic Regression = {0:.3f}".format(lrm.score(X_test, y_test)))
print("Error for Logistic Regression = {0:.3f}".format(1-lrm.score(X_test, y_test)))

LABELS = ['Flood', 'No Flood']

conf_matrix = confusion_matrix(y_test, y_pred_lrm)

plt.figure(figsize =(5, 5))

sns.heatmap(conf_matrix, xticklabels = LABELS,

			yticklabels = LABELS, annot = True, fmt ="d");

plt.title("Confusion matrix: [Logistic Regression]")

plt.ylabel('True class')

plt.xlabel('Predicted class')
plt.rcParams.update({'font.size': 10})
plt.show()

"""## Naive Bayes"""

gnb = GaussianNB()
gnb.fit(X_train, y_train.ravel())
y_pred_gnb = gnb.predict(X_test)

print("Accuracy for Gaussian Naive Bayes = {0:.3f}".format(gnb.score(X_test, y_test)))
print("Error for Gaussian Naive Bayes = {0:.3f}".format(1-gnb.score(X_test, y_test)))

conf_matrix = confusion_matrix(y_test, y_pred_gnb)

plt.figure(figsize =(5, 5))

sns.heatmap(conf_matrix, xticklabels = LABELS,

			yticklabels = LABELS, annot = True, fmt ="d");

plt.title("Confusion matrix: [Gaussian Naive Bayes]")

plt.ylabel('True class')

plt.xlabel('Predicted class')
plt.rcParams.update({'font.size': 10})
plt.show()

"""## Random Forest Classifier

"""

raf = RandomForestClassifier()
raf.fit(X_train, y_train.ravel())
y_pred_raf = raf.predict(X_test)

print("Accuracy for Random Forest = {0:.3f}".format(raf.score(X_test, y_test)))
print("Error for Random Forest = {0:.3f}".format(1-raf.score(X_test, y_test)))

conf_matrix = confusion_matrix(y_test, y_pred_raf)

plt.figure(figsize =(5, 5))

sns.heatmap(conf_matrix, xticklabels = LABELS,

			yticklabels = LABELS, annot = True, fmt ="d");

plt.title("Confusion matrix: [Random Forest]")

plt.ylabel('True class')

plt.xlabel('Predicted class')
plt.rcParams.update({'font.size': 10})
plt.show()

"""##SVM"""

# from sklearn.svm import SVC
# from sklearn.metrics import accuracy_score

# svc=SVC()
# svc.fit(X_train,y_train)
# y_pred=svc.predict(X_test)

# print('Model accuracy score with default hyperparameters: {0:0.4f}'. format(accuracy_score(y_test, y_pred)))

# # instantiate classifier with rbf kernel and C=100
# svc=SVC(C=100.0)
# svc.fit(X_train,y_train)
# y_pred=svc.predict(X_test)

# print('Model accuracy score with rbf kernel and C=100.0 : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))

# # instantiate classifier with linear kernel and C=1000.0
# linear_svc=SVC(kernel='linear', C=1000.0)
# linear_svc.fit(X_train, y_train)

# y_pred=linear_svc1000.predict(X_test)

# print('Model accuracy score with linear kernel and C=1000.0 : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))

# y_pred_train = linear_svc.predict(X_train)
# y_pred_train
# print('Training-set accuracy score: {0:0.4f}'. format(accuracy_score(y_train, y_pred_train)))

# # print the scores on training and test set

# print('Training set score: {:.4f}'.format(linear_svc.score(X_train, y_train)))

# print('Test set score: {:.4f}'.format(linear_svc.score(X_test, y_test)))

# # visualize confusion matrix with seaborn heatmap

# cm_matrix = pd.DataFrame(data=cm, columns=['Actual Positive:1', 'Actual Negative:0'],
#                                  index=['Predict Positive:1', 'Predict Negative:0'])

# sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')

# svc = SVC()
# svc.fit(X_train, y_train)
# preds = svc.predict(X_test)
# print("Scikit-Learn's Support Vector Machine Classifier's prediction accuracy is: %3.2f" % (acc_svc))

# svc_radical =svm.SVC(kernel='rbf',C=1,gamma=0.22)
# svc_radical.fit(X_train,y_train.values.ravel())
# score_svc_radical = svc_radical.score(X_test,y_test)
# print('The accuracy of Radical SVC Model is', score_svc_radical)

"""##XGBoost"""

# from xgboost import XGBRegressor, XGBClassifier
# from sklearn.metrics import mean_absolute_error

# my_model = XGBRegressor()
# my_model.fit(X_train, y_train)

# predictions = my_model.predict(X_test)
# print("Mean Absolute Error: " + str(mean_absolute_error(predictions, y_test)))

# xgb = XGBClassifier(n_estimators=500)
# xgb.fit(X_train, y_train)
# preds = xgb.predict(X_test)
# acc_xgb = (preds == y_test).sum().astype(float) / len(preds)*100
# print("XGBoost's prediction accuracy is: %3.2f" % (acc_xgb))

# xgb_cv = XGBClassifier(n_estimators=100)
# scores = cross_val_score(xgb_cv, X_train, y_train, cv=10, scoring = "accuracy")
# print("Scores:", scores)
# print("Mean:", scores.mean())
# print("Standard Deviation:", scores.std())